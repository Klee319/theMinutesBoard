import React, { useState, useEffect } from 'react'
import { ChromeErrorHandler } from '@/utils/chrome-error-handler'
import { logger } from '@/utils/logger'
import './styles.css'

interface ResearchVoiceButtonProps {
  meetingId: string
  onNewMessage: (userMessage: string, aiResponse: string, voiceTranscripts?: string[]) => void
  disabled?: boolean
}

export const ResearchVoiceButton: React.FC<ResearchVoiceButtonProps> = ({ 
  meetingId,
  onNewMessage,
  disabled = false
}) => {
  const [isRecording, setIsRecording] = useState(false)
  const [isProcessing, setIsProcessing] = useState(false)
  const [recordingStartTime, setRecordingStartTime] = useState<Date | null>(null)
  const [recordingDuration, setRecordingDuration] = useState(0)

  // éŒ²éŸ³ä¸­ã®æ™‚é–“ã‚’æ›´æ–°
  useEffect(() => {
    if (!isRecording || !recordingStartTime) return

    const interval = setInterval(() => {
      const now = new Date()
      const duration = Math.floor((now.getTime() - recordingStartTime.getTime()) / 1000)
      setRecordingDuration(duration)
    }, 1000)

    return () => clearInterval(interval)
  }, [isRecording, recordingStartTime])

  const handleToggleRecording = async () => {
    if (isRecording) {
      // åœæ­¢ã—ã¦å‡¦ç†ã‚’å®Ÿè¡Œ
      setIsRecording(false)
      setIsProcessing(true)

      try {
        // éŸ³å£°è¨˜éŒ²ã‚’åœæ­¢
        const stopResponse = await ChromeErrorHandler.sendMessage({
          type: 'AI_ASSISTANT_STOP',
          payload: { meetingId }
        })

        if (stopResponse?.success && stopResponse.transcripts) {
          // è¨˜éŒ²ã•ã‚ŒãŸéŸ³å£°å†…å®¹ã‚’å–å¾—
          const voiceQuery = stopResponse.transcripts
            .map((t: any) => t.content)
            .join(' ')

          // ãƒªã‚µãƒ¼ãƒã‚’å®Ÿè¡Œ
          const researchResponse = await ChromeErrorHandler.sendMessage({
            type: 'AI_RESEARCH',
            payload: { 
              meetingId,
              question: voiceQuery,
              transcripts: stopResponse.transcripts.map((t: any) => t.content)
            }
          })

          if (researchResponse?.success && researchResponse.response) {
            // ãƒãƒ£ãƒƒãƒˆãƒ­ã‚°ã«è¿½åŠ ï¼ˆéŒ²éŸ³ä¸­ã®å­—å¹•ã‚‚å«ã‚ã‚‹ï¼‰
            const voiceTranscripts = stopResponse.transcripts.map((t: any) => 
              `${t.speaker}: ${t.content}`
            )
            onNewMessage(voiceQuery, researchResponse.response, voiceTranscripts)
            
            // éŒ²éŸ³çŠ¶æ…‹å¤‰æ›´ã‚’é€šçŸ¥
            window.dispatchEvent(new CustomEvent('voiceRecordingStateChanged', {
              detail: { isRecording: false }
            }))
          } else {
            throw new Error(researchResponse?.error || 'ãƒªã‚µãƒ¼ãƒã«å¤±æ•—ã—ã¾ã—ãŸ')
          }
        } else {
          throw new Error(stopResponse?.error || 'éŸ³å£°è¨˜éŒ²ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ')
        }
      } catch (error) {
        logger.error('Failed to process voice research:', error)
        alert('éŸ³å£°ãƒªã‚µãƒ¼ãƒã®å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ')
      } finally {
        setIsProcessing(false)
        setRecordingStartTime(null)
        setRecordingDuration(0)
      }
    } else {
      // éŒ²éŸ³ã‚’é–‹å§‹
      setIsRecording(true)
      setRecordingStartTime(new Date())
      setRecordingDuration(0)

      try {
        const response = await ChromeErrorHandler.sendMessage({
          type: 'AI_ASSISTANT_START',
          payload: { meetingId, type: 'research' }
        })

        if (!response?.success) {
          throw new Error(response?.error || 'éŸ³å£°è¨˜éŒ²ã®é–‹å§‹ã«å¤±æ•—ã—ã¾ã—ãŸ')
        }
        
        // éŒ²éŸ³çŠ¶æ…‹å¤‰æ›´ã‚’é€šçŸ¥
        window.dispatchEvent(new CustomEvent('voiceRecordingStateChanged', {
          detail: { isRecording: true }
        }))
      } catch (error: any) {
        logger.error('Failed to start voice recording:', error)
        alert(error.message || 'éŸ³å£°è¨˜éŒ²ã®é–‹å§‹ã«å¤±æ•—ã—ã¾ã—ãŸ')
        setIsRecording(false)
        setRecordingStartTime(null)
      }
    }
  }

  const formatDuration = (seconds: number): string => {
    const mins = Math.floor(seconds / 60)
    const secs = seconds % 60
    return `${mins}:${secs.toString().padStart(2, '0')}`
  }

  return (
    <div className="research-voice-button-container">
      {isRecording && (
        <div className="recording-hint">
          è³ªå•ã‚’è©±ã—ã¦ãã ã•ã„
        </div>
      )}
      <button
        onClick={handleToggleRecording}
        disabled={disabled || isProcessing}
        className={`research-voice-button ${isRecording ? 'recording' : ''} ${isProcessing ? 'processing' : ''} ${disabled ? 'disabled' : ''}`}
        title={isRecording ? 'éŒ²éŸ³ã‚’åœæ­¢ã—ã¦ãƒªã‚µãƒ¼ãƒå®Ÿè¡Œ' : 'éŸ³å£°ã§ãƒªã‚µãƒ¼ãƒ'}
      >
        {isProcessing ? (
          <span className="spinner"></span>
        ) : isRecording ? (
          <span className="stop-icon">â¹</span>
        ) : (
          <span className="icon">ğŸ™ï¸</span>
        )}
      </button>
      {isRecording && (
        <div className="recording-duration">
          {formatDuration(recordingDuration)}
        </div>
      )}
    </div>
  )
}